{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext                                                                                        \n",
    "from pyspark.sql import SparkSession                                                                                    \n",
    "from pyspark.streaming import StreamingContext                                                                          \n",
    "from pyspark.streaming.kafka import KafkaUtils    \n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.Builder() \\\n",
    "     .appName(\"SparkStreamingKafka\") \\\n",
    "     .master(\"spark://streaming-spark-master:7077\") \\\n",
    "     .config(\"spark.jars\", \"./spark-streaming-kafka-0-8-assembly_2.11-2.4.1.jar\") \\\n",
    "     .config(\"spark.driver.allowMultipleContexts\", \"true\") \\\n",
    "     .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "     .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/hive\") \\\n",
    "     .enableHiveSupport() \\\n",
    "     .getOrCreate()\n",
    "\n",
    "# .config('spark.jars.packages', 'org.apache.spark:spark-streaming-kafka-0-8-assembly_2.11:2.4.1') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = ss.sparkContext\n",
    "ssc = StreamingContext(sc, 5)\n",
    "ss.sparkContext.setLogLevel('WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_rdd1(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        global ss\n",
    "        print(f\"Recieved {len(rdd.collect())} records - transfrom 1\")\n",
    "#         print(rdd.collect())\n",
    "        df = ss.createDataFrame(\n",
    "            rdd,\n",
    "            schema=[\n",
    "                'ID',\n",
    "                'ArrivalTime',\n",
    "                'BusinessLeisure',\n",
    "                'CabinCategory',\n",
    "                'CreationDate',\n",
    "                'CurrencyCode',\n",
    "                'DepartureTime',\n",
    "                'Destination',\n",
    "                'OfficeIdCountry',\n",
    "                'Origin',\n",
    "                'TotalAmount',\n",
    "                'nPAX',\n",
    "                'Record'\n",
    "            ])\n",
    "        df.write.saveAsTable(name='default.trips', format='hive', mode='append')\n",
    "def handle_rdd2(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        global ss\n",
    "        print(f\"Recieved {len(rdd.collect())} records - transfrom 2\")\n",
    "#         print(rdd.collect())\n",
    "        df = ss.createDataFrame(\n",
    "            rdd,\n",
    "            schema=[\n",
    "                'ID',\n",
    "                'ArrivalTime',\n",
    "                'BusinessLeisure',\n",
    "                'CabinCategory',\n",
    "                'CreationDate',\n",
    "                'CurrencyCode',\n",
    "                'DepartureTime',\n",
    "                'Destination',\n",
    "                'OfficeIdCountry',\n",
    "                'Origin',\n",
    "                'TotalAmount',\n",
    "                'nPAX',\n",
    "                'Record'\n",
    "            ])\n",
    "        df.write.saveAsTable(name='default.processed_trips', format='hive', mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = '{\"ID\": 5324, \"ArrivalTime\": \"1452705152\", \"BusinessLeisure\": \"nan\", \"CabinCategory\": \"40\", \"CreationDate\": \"2457203\", \"CurrencyCode\": \"nan\", \"DepartureTime\": \"1451163648\", \"Destination\": \"DPS\", \"OfficeIdCountry\": \"ES\", \"Origin\": \"KJA\", \"TotalAmount\": \"nan\", \"nPAX\": \"1\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(filename: str):\n",
    "    with open(filename, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_and_statistic = read_yaml('mapping_and_statistic.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_list(s):\n",
    "    t = json.loads(s)\n",
    "    results = []\n",
    "    for k, v in t.items():\n",
    "        results.append(v)\n",
    "    results.append(s)\n",
    "    return results\n",
    "\n",
    "def get_continous(x, m):\n",
    "    if str(x) == 'nan':\n",
    "        return 0.0\n",
    "    else:\n",
    "        x = float(x)\n",
    "        return (x - m['statistic']['mean']) / m['statistic']['std']\n",
    "\n",
    "def get_categorical(x, m):\n",
    "    if str(x) == 'nan':\n",
    "        return 0.0\n",
    "    else:\n",
    "        v = m['mapping'][str(x)]\n",
    "        return (v - m['statistic']['mean']) / m['statistic']['std']\n",
    "    \n",
    "def json_to_processed_data(s):\n",
    "    t = json.loads(s)\n",
    "    return [\n",
    "        t['ID'],\n",
    "        get_continous(t['ArrivalTime'], mapping_and_statistic['ArrivalTime']),\n",
    "        get_categorical(t['BusinessLeisure'], mapping_and_statistic['BusinessLeisure']),\n",
    "        get_categorical(t['CabinCategory'], mapping_and_statistic['CabinCategory']),\n",
    "        get_continous(t['CreationDate'], mapping_and_statistic['CreationDate']),\n",
    "        get_categorical(t['CurrencyCode'], mapping_and_statistic['CurrencyCode']),\n",
    "        get_continous(t['DepartureTime'], mapping_and_statistic['DepartureTime']),\n",
    "        get_categorical(t['Destination'], mapping_and_statistic['Destination']),\n",
    "        get_categorical(t['OfficeIdCountry'], mapping_and_statistic['OfficeIdCountry']),\n",
    "        get_categorical(t['Origin'], mapping_and_statistic['Origin']),\n",
    "        get_continous(t['TotalAmount'], mapping_and_statistic['TotalAmount']),\n",
    "        get_continous(t['nPAX'], mapping_and_statistic['nPAX']),\n",
    "        s\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved 671 records - transfrom 1\n",
      "Recieved 671 records - transfrom 2\n",
      "Recieved 3049 records - transfrom 1\n",
      "Recieved 3049 records - transfrom 2\n",
      "Recieved 2756 records - transfrom 1\n",
      "Recieved 2756 records - transfrom 2\n",
      "Recieved 2476 records - transfrom 1\n",
      "Recieved 2476 records - transfrom 2\n",
      "Recieved 1088 records - transfrom 1\n",
      "Recieved 1088 records - transfrom 2\n"
     ]
    }
   ],
   "source": [
    "ks = KafkaUtils.createDirectStream(\n",
    "    ssc, ['trips'], {'metadata.broker.list': 'kafka-broker-1:9093,kafka-broker-2:9093'})\n",
    "lines = ks.map(lambda x: x[1])\n",
    "\n",
    "# transform = lines.map(lambda tweet: (tweet, int(len(tweet.split())), int(len(tweet))))\n",
    "transform1 = lines.map(lambda tripInfo: json_to_list(tripInfo))\n",
    "transform1.foreachRDD(handle_rdd1)\n",
    "\n",
    "transform2 = lines.map(lambda tripInfo: json_to_processed_data(tripInfo))\n",
    "transform2.foreachRDD(handle_rdd2)\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
