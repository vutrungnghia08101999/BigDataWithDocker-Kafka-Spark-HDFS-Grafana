{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext                                                                                        \n",
    "from pyspark.sql import SparkSession                                                                                    \n",
    "from pyspark.streaming import StreamingContext                                                                          \n",
    "from pyspark.streaming.kafka import KafkaUtils    \n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = SparkSession.Builder() \\\n",
    "#      .appName(\"SparkStreamingKafka\") \\\n",
    "#      .master(\"spark://streaming-spark-master:7077\") \\\n",
    "#      .config(\"spark.jars\", \"./spark-streaming-kafka-0-8-assembly_2.11-2.4.1.jar\") \\\n",
    "#      .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/\") \\\n",
    "#      .getOrCreate()\n",
    "ss = SparkSession.Builder() \\\n",
    "     .appName(\"SparkSpeedStreamingKafka\") \\\n",
    "     .master(\"spark://speed-processing-spark-master:7077\") \\\n",
    "     .config(\"spark.jars\", \"./spark-sql-kafka-0-10_2.11-2.4.1.jar,./kafka-clients-2.0.0.jar\") \\\n",
    "     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ss \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-broker-1:9093,kafka-broker-2:9093,kafka-broker-3:9093\") \\\n",
    "  .option(\"subscribe\", \"trips\") \\\n",
    "  .load()\n",
    "# line.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "# Split the lines into words\n",
    "# words = lines.select(\n",
    "#    explode(\n",
    "#        split(lines.value, \" \")\n",
    "#    ).alias(\"word\")\n",
    "# )\n",
    "\n",
    "s = line.select(\"value\")\n",
    "\n",
    "# # Generate running word count\n",
    "# wordCounts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = s \\\n",
    "    .writeStream \\\n",
    "    .trigger(continuous='5 seconds') \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka-broker-1:9093,kafka-broker-2:9093,kafka-broker-3:9093\") \\\n",
    "    .option(\"topic\", \"real-time-statistic\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
