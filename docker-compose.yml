version: "3"
services:
############################ HDFS #################################
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - 8020:8020
      - 50070:50070
  datanode-1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode-1
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075

  datanode-2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode-2
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
    ports:
      - 50076:50075
  datanode-3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode-3
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
    ports:
      - 50077:50075

############################## Spark #################################  
  streaming-spark-master:
    image: spark-master:spark2.4.1-python3.7-hadoop2.7
    container_name: streaming-spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - $PWD/../shared:/data
  streaming-spark-worker-1:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: streaming-spark-worker-1
    depends_on:
      - streaming-spark-master
    environment:
      - "SPARK_MASTER=spark://streaming-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"
  streaming-spark-worker-2:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: streaming-spark-worker-2
    depends_on:
      - streaming-spark-master
    environment:
      - "SPARK_MASTER=spark://streaming-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"
  streaming-spark-worker-3:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: streaming-spark-worker-3
    depends_on:
      - streaming-spark-master
    environment:
      - "SPARK_MASTER=spark://streaming-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"

  batch-processing-spark-master:
    image: spark-master:spark2.4.1-python3.7-hadoop2.7
    container_name: batch-processing-spark-master
    ports:
      - "8083:8080"
      - "7078:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - $PWD/../shared:/data
  batch-processing-spark-worker-1:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: batch-processing-spark-worker-1
    depends_on:
      - batch-processing-spark-master
    environment:
      - "SPARK_MASTER=spark://batch-processing-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"
  batch-processing-spark-worker-2:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: batch-processing-spark-worker-2
    depends_on:
      - batch-processing-spark-master
    environment:
      - "SPARK_MASTER=spark://batch-processing-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"
  batch-processing-spark-worker-3:
    image: spark-worker:spark2.4.1-python3.7-hadoop2.7
    container_name: batch-processing-spark-worker-3
    depends_on:
      - batch-processing-spark-master
    environment:
      - "SPARK_MASTER=spark://batch-processing-spark-master:7077"
      - "SPARK_WORKER_CORES=1"
      - "SPARK_WORKER_MEMORY=1G"
      - "SPARK_DRIVER_MEMORY=128m"
      - "SPARK_EXECUTOR_MEMORY=256m"

############################## Kafka #################################
  zookeeper:
    image: zookeeper:3.4.10
    container_name: zookeeper
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888
      ZOO_TICK_TIME: 15000
    ports:
      - 2181:2181      
  kafka-broker-1:
    image: wurstmeister/kafka:2.12-2.2.1
    container_name: kafka-broker-1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://kafka-broker-1:9093,OUTSIDE://localhost:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_LISTENERS=INSIDE://kafka-broker-1:9093,OUTSIDE://0.0.0.0:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE

  kafka-broker-2:
    image: wurstmeister/kafka:2.12-2.2.1
    container_name: kafka-broker-2
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://kafka-broker-2:9093,OUTSIDE://localhost:9094
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_LISTENERS=INSIDE://kafka-broker-2:9093,OUTSIDE://0.0.0.0:9094
      - KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE
  kafka-broker-3:
    image: wurstmeister/kafka:2.12-2.2.1
    container_name: kafka-broker-3
    depends_on:
      - zookeeper
    ports:
      - "9095:9095"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://kafka-broker-3:9093,OUTSIDE://localhost:9095
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_LISTENERS=INSIDE://kafka-broker-3:9093,OUTSIDE://0.0.0.0:9095
      - KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE
  kafka_manager:
    image: hlebalbau/kafka-manager:2.0.0.2
    container_name: kafka_manager
    ports:
      - "9000:9000"
    environment:
      - ZK_HOSTS=zookeeper:2181
      - KAFKA_MANAGER_AUTH_ENABLED=true
      - KAFKA_MANAGER_USERNAME=hai
      - KAFKA_MANAGER_PASSWORD=hai
    command: -Dpidfile.path=/dev/null

############################## Notebook #################################
  dashboard-notebook:
    image: dashboard-notebook:spark2.4.1-python3.7-hadoop2.7-hive
    container_name: dashboard-notebook
    ports:
      - "8888:8888"
    volumes:
      - $PWD/src/notebook-dashboard:/home/jovyan/work
    environment:
      - JUPYTER_TOKEN=admin

  pyspark-notebook-streaming:
    image: pyspark-notebook:spark2.4.1-python3.7-hadoop2.7
    container_name: pyspark-notebook-streaming
    ports:
      - "8889:8888"
    volumes:
      - $PWD/src/notebook-spark-streaming-slow-branch:/home/jovyan/work
    environment:
      - JUPYTER_TOKEN=admin

networks:
  default:
    external:
      name: bigdata
